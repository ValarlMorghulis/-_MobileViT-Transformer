# 代码链接及使用说明

## 代码链接

[CVNets: A library for training computer vision networks](https://github.com/apple/ml-cvnets)

### 项目目录

```
ml-cvnets/
├── common
├── config
├── cvnets
│   ├── anchor_generator
│   ├── layers
│   ├── misc
│   ├── models  (*)
│   │   ├── classification
│   │   ├── detection
│   │   ├── neural_augmentation
│   │   ├── segmentation
│   │   └── video_classification
│   └── modules  (*)
├── data
│   ├── collate_fns
│   ├── datasets  (*)
│   ├── loader
│   ├── sampler  (*)
│   ├── transforms
│   └── video_reader
├── docs
├── engine  (*)
│   ├── detection_utils
│   └── segmentation_utils
├── loss_fn
├── metrics
├── optim
|   └── scheduler
├── options/
├── tests/
├── utils/
├── .gitignore
├── ACKNOWLEDGEMENTS
├── CODE_OF_CONDUCT.md
├── CONTRIBUTING.md
├── LICENSE
├── Makefile
├── README.md
├── conftest.py
├── constraints.txt
├── main_benchmark.py
├── main_conversion.py
├── main_eval.py
├── main_loss_landscape.py
├── main_train.py
├── pyproject.toml
├── requirements.txt
├── requirements_docs.txt
└── setup.py
```

### 项目介绍

+ **common/**: 包含项目中常用的工具和函数。
+ **config/**: 包含项目的配置文件。
+ **cvnets/**: 核心代码库，包含各种计算机视觉模型的实现。
+ **data/**: 数据处理相关的代码和工具。
+ **docs/**: 项目文档。
+ **engine/**: 训练和评估引擎的实现。
+ **examples/**: 示例代码，展示如何使用 CVNets 进行训练和评估。
+ **loss_fn/**: 损失函数的实现。
+ **loss_landscape/**: 损失景观分析的代码。
+ **metrics/**: 评估指标的实现。
+ **optim/**: 优化器的实现。
+ **options/**: 命令行选项的处理。
+ **tests/**: 测试代码。
+ **utils/**: 实用工具函数。
+ **.gitignore**: Git 忽略文件。
+ **ACKNOWLEDGEMENTS**: 致谢。
+ **CODE_OF_CONDUCT.md**: 行为准则。
+ **CONTRIBUTING.md**: 贡献指南。
+ **LICENSE**: 许可证。
+ **Makefile**: Makefile 文件。
+ **README.md**: 项目说明文档。
+ **conftest.py**: Pytest 配置文件。
+ **constraints.txt**: 依赖约束文件。
+ **main_benchmark.py**: 用于基准测试的主文件。可以对不同模型进行基准测试，比较它们的性能。
+ **main_conversion.py**: 用于模型转换的主文件。可以将 PyTorch 模型转换为 CoreML 模型，以便在移动设备上使用。
+ **main_eval.py**: 用于评估已训练模型的主文件。可以加载预训练模型并对其进行评估，输出评估结果。
+ **main_loss_landscape.py**: 用于损失景观分析的主文件。可以生成和可视化模型的损失景观，帮助理解模型的训练过程。
+ **main_train.py**: 用于训练计算机视觉模型的主文件。可以通过命令行参数配置训练过程，包括模型类型、数据集、优化器等。
+ **pyproject.toml**: 项目配置文件。
+ **requirements.txt**: 依赖文件。
+ **requirements_docs.txt**: 文档依赖文件。
+ **setup.py**: 安装CVNets的配置文件。

## 使用说明

### 安装CVNets

```bash
# 使用Git克隆代码
git clone git@github.com:apple/ml-cvnets.git
cd ml-cvnets

# 创建虚拟环境并激活(使用Conda)
conda create -n cvnets python=3.10.8
conda activate cvnets

# 配置虚拟环境和CVNet包
pip install -r requirements.txt -c constraints.txt
pip install --editable .
```

### 模型的训练和评估

1. 分类模型

在CVNets中，提供了一些预定义的配置文件，用于训练和评估不同的计算机视觉模型。这些配置文件位于 `config/classification`目录下。同时，作者也提供了以下模型的预训练权重和配置文件：

| Model         | Parameters | Top-1 | Pretrained weights                                                                                     | Config file                                                                                              |
| ------------- | ---------- | ----- | ------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------- |
| MobileViT-XXS | 1.3 M      | 69.0  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets/classification/mobilevit_xxs.pt) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets/classification/mobilevit_xxs.yaml) |
| MobileViT-XS  | 2.3 M      | 74.7  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets/classification/mobilevit_xs.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets/classification/mobilevit_xs.yaml)  |
| MobileViT-S   | 5.6 M      | 78.3  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets/classification/mobilevit_s.pt)   | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets/classification/mobilevit_s.yaml)   |

本文仅展示与MobileViT模型相关的代码。如需下载其他模型的预训练权重和配置文件，可以访问 [Model Zoo](https://github.com/apple/ml-cvnets/blob/main/docs/source/en/general/README-model-zoo.md)。

例如，MobileViT-S模型可以通过在命令行中输入以下代码进行训练：

```bash
export CFG_FILE="config/classification/imagenet/mobilevit.yaml"
cvnets-train --common.config-file $CFG_FILE --common.results-loc classification_results
```

训练完成后，可以使用以下命令评估模型：

```bash
cvnets-eval --common.config-file $CFG_FILE \
   --common.results-loc classification_results \
   --model.classification.pretrained classification_results/checkpoint_ema_best.pt
```

2. 检测模型

在CVNets中，提供了一些预定义的配置文件，用于训练和评估不同的计算机视觉模型。这些配置文件位于 `config/detection`目录下。同时，作者也提供了以下模型的预训练权重和配置文件：

| Model                | Parameters | MAP   | Pretrained weights                                                                                                           | Config file                                                                                                                    | Logs                                                                                                                           |
| -------------------- | ---------- | ----- | ---------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------ |
| SSD ResNet-50        | 28.5 M     | 29.98 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/coco-ssd-resnet-50.pt)                    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/coco-ssd-resnet-50.yaml)                    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/coco-ssd-resnet-50.logs)                    |
| SSD MobileViTv2-0.5  | 2.0 M      | 21.24 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-0.5.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-0.5.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-0.5.logs)  |
| SSD MobileViTv2-0.75 | 3.6 M      | 24.57 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-0.75.pt) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-0.75.yaml) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-0.75.logs) |
| SSD MobileViTv2-1.0  | 5.6 M      | 26.47 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.0.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.0.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.0.logs)  |
| SSD MobileViTv2-1.25 | 8.2 M      | 27.85 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.25.pt) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.25.yaml) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.25.logs) |
| SSD MobileViTv2-1.5  | 11.3 M     | 28.83 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.5.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.5.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.5.logs)  |
| SSD MobileViTv2-1.75 | 14.9 M     | 29.52 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.75.pt) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.75.yaml) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-1.75.logs) |
| SSD MobileViTv2-2.0  | 19.1 M     | 30.21 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-2.0.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-2.0.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/detection/mobilevitv2/coco-ssd-mobilevitv2-2.0.logs)  |

由于在CVNets中没有提供训练MobileViT-S模型的预训练权重，因此需要自己对模型进行训练。

例如，MobileViT-S模型可以通过在命令行中输入以下代码进行训练：

```bash
export CONFIG_FILE="config/detection/ssd_coco/mobilevit.yaml"
export MODEL_WTS="path/to/imagenet_pretrained_mobilevit_weights.pt"
PYTHONWARNINGS="ignore" cvnets-train \
    --common.config-file $CONFIG_FILE \
    --common.results-loc ssdlite_mobilevit_results \
    --model.classification.pretrained=$MODEL_WTS
```

训练完成后，可以使用以下命令评估模型：

```bash
CUDA_VISIBLE_DEVICES=0 cvnets-eval-det \
    --common.config-file $CONFIG_FILE \
    --common.results-loc ssdlite_mobilevit_results \
    --model.detection.pretrained $SSDLITE_MODEL_WEIGHTS \
    --model.detection.n-classes 81 \
    --evaluation.detection.resize-input-images \
    --evaluation.detection.mode validation_set
```

3. 分割模型

在CVNets中，提供了一些预定义的配置文件，用于训练和评估不同的计算机视觉模型。这些配置文件位于 `config/segmentation`目录下。同时，作者也提供了以下模型的预训练权重和配置文件：

+ **ADE20K Dataset**
  | Model                      | Parameters | mIoU  | Pretrained weights                                                                                                                      | Config file                                                                                                                               | Logs                                                                                                                                      |
  | -------------------------- | ---------- | ----- | --------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
  | DeepLabv3 MobileNetv2      | 8.0 M      | 35.20 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/deeplabv3-mobilenetv2.pt)                  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/deeplabv3-mobilenetv2.yaml)                  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/deeplabv3-mobilenetv2.logs)                  |
  | PSPNet MobileViTv2-0.5     | 3.6 M      | 31.77 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-0.5.pt)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-0.5.yaml)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-0.5.logs)     |
  | PSPNet MobileViTv2-0.75    | 6.2 M      | 35.22 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-0.75.pt)    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-0.75.yaml)    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-0.75.logs)    |
  | PSPNet MobileViTv2-1.0     | 9.4 M      | 36.57 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.0.pt)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.0.yaml)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.0.logs)     |
  | PSPNet MobileViTv2-1.25    | 13.2 M     | 38.76 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.25.pt)    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.25.yaml)    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.25.logs)    |
  | PSPNet MobileViTv2-1.5     | 17.6 M     | 38.74 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.5.pt)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.5.yaml)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.5.logs)     |
  | PSPNet MobileViTv2-1.75    | 22.5 M     | 39.82 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.75.pt)    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.75.yaml)    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/pspnet-mobilevitv2-1.75.logs)    |
  | DeepLabv3 MobileViTv2-0.5  | 6.3 M      | 31.93 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-0.5.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-0.5.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-0.5.logs)  |
  | DeepLabv3 MobileViTv2-0.75 | 9.6 M      | 34.70 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-0.75.pt) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-0.75.yaml) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-0.75.logs) |
  | DeepLabv3 MobileViTv2-1.0  | 13.4 M     | 37.06 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.0.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.0.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.0.logs)  |
  | DeepLabv3 MobileViTv2-1.25 | 17.7 M     | 38.42 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.25.pt) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.25.yaml) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.25.logs) |
  | DeepLabv3 MobileViTv2-1.5  | 22.6 M     | 38.91 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.5.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.5.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.5.logs)  |
  | DeepLabv3 MobileViTv2-1.75 | 28.1 M     | 39.53 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.75.pt) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.75.yaml) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-1.75.logs) |
  | DeepLabv3 MobileViTv2-2.0  | 34.0 M     | 40.94 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-2.0.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-2.0.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/ade20k/mobilevitv2/deeplabv3-mobilevitv2-2.0.logs)  |
+ **Pascal VOC 2012 Dataset**
  | Model                      | Parameters | mIoU  | Pretrained weights                                                                                                                         | Config file                                                                                                                                  | Logs                                                                                                                                         |
  | -------------------------- | ---------- | ----- | ------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- |
  | DeepLabv3 MobileViTv1      | 8.5 M      | 79.44 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/deeplabv3-mobilevitv1.pt)                  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/deeplabv3-mobilevitv1.yaml)                  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/deeplabv3-mobilevitv1.logs)                  |
  | PSPNet MobileViTv2-0.5     | 3.6 M      | 74.62 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-0.5.pt)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-0.5.yaml)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-0.5.logs)     |
  | PSPNet MobileViTv2-0.75    | 6.2 M      | 77.44 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-0.75.pt)    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-0.75.yaml)    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-0.75.logs)    |
  | PSPNet MobileViTv2-1.0     | 9.4 M      | 78.92 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-1.0.pt)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-1.0.yaml)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-1.0.logs)     |
  | PSPNet MobileViTv2-1.25    | 13.2 M     | 79.40 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-1.25.pt)    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-1.25.yaml)    | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-1.25.logs)    |
  | PSPNet MobileViTv2-1.5     | 17.5 M     | 79.93 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-1.5.pt)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-1.5.yaml)     | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/pspnet-mobilevitv2-1.5.logs)     |
  | DeepLabv3 MobileViTv2-0.5  | 6.2 M      | 75.07 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-0.5.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-0.5.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-0.5.logs)  |
  | DeepLabv3 MobileViTv2-1.0  | 13.3 M     | 78.94 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-1.0.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-1.0.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-1.0.logs)  |
  | DeepLabv3 MobileViTv2-1.25 | 17.7 M     | 79.68 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-1.25.pt) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-1.25.yaml) | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-1.25.logs) |
  | DeepLabv3 MobileViTv2-1.5  | 22.6 M     | 80.30 | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-1.5.pt)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-1.5.yaml)  | [Link](https://docs-assets.developer.apple.com/ml-research/models/cvnets-v2/segmentation/pascalvoc/mobilevitv2/deeplabv3-mobilevitv2-1.5.logs)  |

由于在CVNets中没有提供训练MobileViT-S模型的配置文件，因此需要自己创建一个配置文件。例如，可以创建一个名为 `config/segmentation/mobilevit.yaml`的配置文件。

接着，可以通过以下命令训练MobileViT-S模型：

```bash
export CONFIG_FILE="path/to/your/segmentation_config.yaml"
export MODEL_WTS="path/to/imagenet_pretrained_mobilevit_weights.pt"
PYTHONWARNINGS="ignore" cvnets-train \
    --common.config-file $CONFIG_FILE \
    --common.results-loc segmentation_results \
    --model.classification.pretrained=$MODEL_WTS
```

训练完成后，可以使用以下命令评估模型：

```bash
export CONFIG_FILE="path/to/your/segmentation_config.yaml"
export SEGMENTATION_MODEL_WEIGHTS="path/to/trained_model_weights.pt"
CUDA_VISIBLE_DEVICES=0 cvnets-eval-seg \
    --common.config-file $CONFIG_FILE \
    --common.results-loc segmentation_results \
    --model.segmentation.pretrained $SEGMENTATION_MODEL_WEIGHTS \
    --evaluation.segmentation.resize-input-images \
    --evaluation.segmentation.mode validation_set
```

### 将训练好的模型转换为CoreML模型

由于本论文的目的是得到一个能够移动设备上高效运行的模型，而PyTorch模型无法直接在移动设备上运行，因此需要将训练好的模型转换为CoreML模型(Apple为iOS设备提供的机器学习框架)。

注意：以下代码默认使用MacOS系统。

1. 分类模型

```bash
export CONFIG_FILE="LOCATION_OF_CONFIG_FILE"
export MODEL_WEIGHTS="LOCATION_OF_MODEL_WEIGHT_FILE"
cvnets-convert --common.config-file $CONFIG_FILE \
   --common.results-loc coreml_models_cls \
   --model.classification.pretrained $MODEL_WEIGHTS \
   --conversion.coreml-extn mlmodel
```

2. 检测模型

```bash
export CONFIG_FILE="LOCATION_OF_CONFIG_FILE"
export MODEL_WEIGHTS="LOCATION_OF_MODEL_WEIGHT_FILE"
export N_CLASSES="NUMBER_OF_CLASSES"
cvnets-convert --common.config-file $CONFIG_FILE \
   --common.results-loc coreml_models_det \
   --model.detection.pretrained $MODEL_WEIGHTS \
   --conversion.coreml-extn mlmodel \
   --model.detection.n-classes $N_CLASSES
```

3. 分割模型

```bash
export CONFIG_FILE="LOCATION_OF_CONFIG_FILE"
export MODEL_WEIGHTS="LOCATION_OF_MODEL_WEIGHT_FILE"
export N_CLASSES="NUMBER_OF_CLASSES"
cvnets-convert --common.config-file $CONFIG_FILE \
   --common.results-loc coreml_models_res \
   --model.segmentation.pretrained $MODEL_WEIGHTS \
   --conversion.coreml-extn mlmodel \
   --model.segmentation.n-classes $N_CLASSES
```
